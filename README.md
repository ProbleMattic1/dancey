# DanceApp

Autogenerated README placeholder.


## Docker Compose boot with migrations
The backend container waits for Postgres, runs `alembic upgrade head`, then starts the API automatically.

## Alembic autogenerate
To create a new migration from SQLAlchemy models:
```bash
alembic revision --autogenerate -m "your change"
alembic upgrade head
```

## Pose inference with TFLite (optional)
Set `POSE_TFLITE_PATH=backend/models/movenet_singlepose_lightning_4.tflite` to use TFLite instead of ONNX.


## Optional Celery pipeline
- Bring up Redis + Celery worker: `docker compose -f infra/docker-compose.yml up -d redis celery`
- Set `USE_CELERY=1` on backend to enqueue Celery tasks instead of Kafka.

## Helm chart
- Package/install:
  ```bash
  helm install danceapp helm/danceapp --set image.backend=<img>,image.frontend=<img>
  ```

## E2E test
- With local docker-compose running:
  ```bash
  export E2E=true
  pytest tests/test_e2e.py -q
  ```


## Notifications (Slack/Discord)
Set these env vars on the backend service (compose or k8s) to receive notifications when analysis finishes or segments are indexed:
- `SLACK_WEBHOOK_URL`
- `DISCORD_WEBHOOK_URL`

## Kubernetes Job (Helm)
Trigger a one-off analysis for a specific video:
1. In `helm/danceapp/values.yaml`, set:
   ```yaml
   job:
     enabled: true
     videoId: "vid_abc123"
   ```
2. Apply the chart:
   ```bash
   helm upgrade --install danceapp helm/danceapp
   ```
This creates a Job using the backend image that calls the API to queue analysis for `videoId`.
